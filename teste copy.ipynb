{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4278ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Excel gerado: c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\report_mapeado.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font\n",
    "\n",
    "def flatten_json(y, parent_key='', sep='.'):\n",
    "    \"\"\"\n",
    "    Função para achatar um JSON aninhado em um dicionário plano.\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    if isinstance(y, list):\n",
    "        # Se o JSON no nível superior for uma lista, processa cada item\n",
    "        for i, item in enumerate(y):\n",
    "            items.extend(flatten_json(item, f\"{parent_key}[{i}]\", sep=sep).items())\n",
    "    elif isinstance(y, dict):\n",
    "        # Se o JSON for um dicionário, processa normalmente\n",
    "        for k, v in y.items():\n",
    "            new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "            if isinstance(v, (dict, list)):\n",
    "                # Processa recursivamente se for um dicionário ou lista\n",
    "                items.extend(flatten_json(v, new_key, sep=sep).items())\n",
    "            else:\n",
    "                try:\n",
    "                    # Tenta carregar o valor como JSON (caso seja um JSON em string)\n",
    "                    parsed_value = json.loads(v) if isinstance(v, str) and v.strip().startswith(('{', '[')) else v\n",
    "                    if isinstance(parsed_value, (dict, list)):\n",
    "                        # Se o valor for um JSON válido, processa recursivamente\n",
    "                        items.extend(flatten_json(parsed_value, new_key, sep=sep).items())\n",
    "                    else:\n",
    "                        items.append((new_key, parsed_value))\n",
    "                except (ValueError, TypeError):\n",
    "                    # Se não for um JSON válido, adiciona o valor diretamente\n",
    "                    items.append((new_key, v))\n",
    "    else:\n",
    "        # Se o JSON for um valor simples (não lista ou dicionário)\n",
    "        items.append((parent_key, y))\n",
    "    return dict(items)\n",
    "\n",
    "def map_json_to_excel(json_file, output_excel):\n",
    "    \"\"\"\n",
    "    Função para mapear um arquivo JSON e gerar um Excel com o conteúdo mapeado.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Carrega o arquivo JSON\n",
    "        with open(json_file, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Achata o JSON\n",
    "        flattened_data = flatten_json(data)\n",
    "        \n",
    "        # Cria um novo workbook do Excel\n",
    "        wb = openpyxl.Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"JSON Mapeado\"\n",
    "        \n",
    "        # Adiciona cabeçalhos\n",
    "        ws.append([\"Chave\", \"Valor\"] + [f\"Parte {i+1}\" for i in range(10)])  # Adiciona colunas extras para as partes da chave\n",
    "        header_font = Font(bold=True)\n",
    "        for cell in ws[1]:\n",
    "            cell.font = header_font\n",
    "        \n",
    "        # Adiciona os dados mapeados\n",
    "        for key, value in flattened_data.items():\n",
    "            key_parts = key.split('.')  # Divide a chave pelo separador \".\"\n",
    "            row = [key, value] + key_parts  # Adiciona as partes da chave como colunas extras\n",
    "            ws.append(row)\n",
    "        \n",
    "        # Ajusta a largura das colunas\n",
    "        for column in ws.columns:\n",
    "            max_length = 0\n",
    "            column_letter = column[0].column_letter  # Obtém a letra da coluna\n",
    "            for cell in column:\n",
    "                try:\n",
    "                    if cell.value:\n",
    "                        max_length = max(max_length, len(str(cell.value)))\n",
    "                except:\n",
    "                    pass\n",
    "            ws.column_dimensions[column_letter].width = max_length + 2\n",
    "        \n",
    "        # Salva o arquivo Excel\n",
    "        wb.save(output_excel)\n",
    "        print(f\"Arquivo Excel gerado: {output_excel}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "# Caminho para o arquivo JSON e saída do Excel\n",
    "json_file = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report.json\"\n",
    "output_excel = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\report_mapeado.xlsx\"\n",
    "\n",
    "# Executa o mapeamento\n",
    "map_json_to_excel(json_file, output_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427a45da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Excel gerado: c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\report_compilado.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def process_json(json_data):\n",
    "    \"\"\"\n",
    "    Processa o JSON e gera as tabelas df_Sections, df_VisualContainers e df_VC_complemento.\n",
    "    \"\"\"\n",
    "    # Listas para armazenar os dados das tabelas\n",
    "    sections_data = []\n",
    "    visual_containers_data = []\n",
    "    vc_complemento_data = []\n",
    "\n",
    "    # ID único para sections e visualContainers\n",
    "    section_id_counter = 1\n",
    "    visual_container_id_counter = 1\n",
    "\n",
    "    # Processa as sections\n",
    "    for section in json_data.get(\"sections\", []):\n",
    "        # Cria um ID único para a seção\n",
    "        section_id = section_id_counter\n",
    "        section_id_counter += 1\n",
    "\n",
    "        # Adiciona os dados da seção à tabela df_Sections\n",
    "        sections_data.append({\n",
    "            \"id_section\": section_id,\n",
    "            \"sections\": section.get(\"name\"),\n",
    "            \"DisplayName\": section.get(\"displayName\"),\n",
    "            \"DisplayOption\": section.get(\"displayOption\"),\n",
    "            \"height\": section.get(\"height\"),\n",
    "            \"width\": section.get(\"width\"),\n",
    "            \"VisualContainers_id\": [],\n",
    "            \"config\": json.dumps(section)  # Inclui o JSON completo da seção no final\n",
    "        })\n",
    "\n",
    "        # Processa os visualContainers dentro da seção\n",
    "        for visual_container in section.get(\"visualContainers\", []):\n",
    "            # Cria um ID único para o visualContainer\n",
    "            visual_container_id = visual_container_id_counter\n",
    "            visual_container_id_counter += 1\n",
    "\n",
    "            # Adiciona o ID do visualContainer à seção correspondente\n",
    "            sections_data[-1][\"VisualContainers_id\"].append(visual_container_id)\n",
    "\n",
    "            # Processa o campo config do visualContainer\n",
    "            config = json.loads(visual_container.get(\"config\", \"{}\"))\n",
    "            single_visual = config.get(\"singleVisual\", {})\n",
    "            prototype_query = single_visual.get(\"prototypeQuery\", {}).get(\"Select\", [])\n",
    "\n",
    "            # Determina se é um grupo (visualType vazio)\n",
    "            visual_type = single_visual.get(\"visualType\", \"\")\n",
    "            is_group = visual_type == \"\"\n",
    "\n",
    "            # Adiciona os dados do visualContainer à tabela df_VisualContainers\n",
    "            visual_containers_data.append({\n",
    "                \"VisualContainers_id\": visual_container_id,\n",
    "                \"id_section\": section_id,\n",
    "                \"height\": visual_container.get(\"height\"),\n",
    "                \"width\": visual_container.get(\"width\"),\n",
    "                \"x\": visual_container.get(\"x\"),\n",
    "                \"y\": visual_container.get(\"y\"),\n",
    "                \"z\": visual_container.get(\"z\"),\n",
    "                \"name\": config.get(\"name\"),\n",
    "                \"visualType\": \"group\" if is_group else visual_type,\n",
    "                \"config\": visual_container.get(\"config\")  # Inclui o JSON completo no final\n",
    "            })\n",
    "\n",
    "            # Processa o prototypeQuery.Select para identificar colunas, medidas e agregações\n",
    "            for select_item in prototype_query:\n",
    "                tipo = None\n",
    "                table = None\n",
    "                column = None\n",
    "                aggregation = None\n",
    "                expression_type = None\n",
    "\n",
    "                # Determina o tipo com base nos campos presentes\n",
    "                if \"Column\" in select_item:\n",
    "                    tipo = \"column\"\n",
    "                    expression_type = \"Column\"\n",
    "                    table = select_item[\"Column\"].get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\")\n",
    "                    column = select_item[\"Column\"].get(\"Property\")\n",
    "                elif \"Aggregation\" in select_item:\n",
    "                    tipo = \"aggregation\"\n",
    "                    expression_type = \"Aggregation\"\n",
    "                    aggregation_value = select_item[\"Aggregation\"].get(\"Function\")\n",
    "                    aggregation_map = {1: \"SUM\", 2: \"AVG\", 3: \"COUNT\", 4: \"MIN\", 5: \"MAX\"}\n",
    "                    aggregation = aggregation_map.get(aggregation_value, f\"Unknown ({aggregation_value})\")\n",
    "                    table = select_item[\"Aggregation\"].get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\")\n",
    "                    column = select_item[\"Aggregation\"].get(\"Expression\", {}).get(\"Property\")\n",
    "                elif \"Measure\" in select_item:\n",
    "                    tipo = \"measure\"\n",
    "                    expression_type = \"Measure\"\n",
    "                    table = select_item[\"Measure\"].get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\")\n",
    "                    column = select_item[\"Measure\"].get(\"Property\")\n",
    "\n",
    "                # Adiciona os dados à tabela df_VC_complemento\n",
    "                vc_complemento_data.append({\n",
    "                    \"VisualContainers_id\": visual_container_id,\n",
    "                    \"tipo\": tipo,\n",
    "                    \"Tabela\": table,\n",
    "                    \"nome\": column,\n",
    "                    \"nomeNoVisual\": select_item.get(\"NativeReferenceName\", column),\n",
    "                    \"Agregacao\": aggregation,\n",
    "                    \"expression\": expression_type\n",
    "                })\n",
    "\n",
    "    # Converte as listas em DataFrames\n",
    "    df_sections = pd.DataFrame(sections_data)\n",
    "    df_visual_containers = pd.DataFrame(visual_containers_data)\n",
    "    df_vc_complemento = pd.DataFrame(vc_complemento_data)\n",
    "\n",
    "    # Ajusta o campo VisualContainers_id em df_Sections para ser uma string (ou lista, se necessário)\n",
    "    df_sections[\"VisualContainers_id\"] = df_sections[\"VisualContainers_id\"].apply(lambda x: \", \".join(map(str, x)))\n",
    "\n",
    "    return df_sections, df_visual_containers, df_vc_complemento\n",
    "\n",
    "# Caminho para o arquivo JSON\n",
    "json_file = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report.json\"\n",
    "\n",
    "# Carrega o JSON\n",
    "with open(json_file, 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Processa o JSON e gera as tabelas\n",
    "df_sections, df_visual_containers, df_vc_complemento = process_json(json_data)\n",
    "\n",
    "# Caminho para salvar o arquivo Excel\n",
    "output_excel = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\report_compilado.xlsx\"\n",
    "\n",
    "# Exporta os DataFrames para um único arquivo Excel\n",
    "with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
    "    df_sections.to_excel(writer, sheet_name=\"Sections\", index=False)\n",
    "    df_visual_containers.to_excel(writer, sheet_name=\"VisualContainers\", index=False)\n",
    "    df_vc_complemento.to_excel(writer, sheet_name=\"VC_Complemento\", index=False)\n",
    "\n",
    "print(f\"Arquivo Excel gerado: {output_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c9be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def process_sections(json_data):\n",
    "    \"\"\"\n",
    "    Processa a chave 'sections' e gera as tabelas df_sections, df_visual_containers e df_vc_complemento.\n",
    "    \"\"\"\n",
    "    # Listas para armazenar os dados das tabelas\n",
    "    sections_data = []\n",
    "    visual_containers_data = []\n",
    "    vc_complemento_data = []\n",
    "\n",
    "    # ID único para sections e visualContainers\n",
    "    section_id_counter = 1\n",
    "    visual_container_id_counter = 1\n",
    "\n",
    "    # Processa as sections\n",
    "    for section in json_data.get(\"sections\", []):\n",
    "        # Cria um ID único para a seção\n",
    "        section_id = section_id_counter\n",
    "        section_id_counter += 1\n",
    "\n",
    "        # Adiciona os dados da seção à tabela df_sections\n",
    "        sections_data.append({\n",
    "            \"id_section\": section_id,\n",
    "            \"sections\": section.get(\"name\"),\n",
    "            \"DisplayName\": section.get(\"displayName\"),\n",
    "            \"DisplayOption\": section.get(\"displayOption\"),\n",
    "            \"height\": section.get(\"height\"),\n",
    "            \"width\": section.get(\"width\"),\n",
    "            \"VisualContainers_id\": [],\n",
    "            \"config\": json.dumps(section)  # Inclui o JSON completo da seção no final\n",
    "        })\n",
    "\n",
    "        # Processa os visualContainers dentro da seção\n",
    "        for visual_container in section.get(\"visualContainers\", []):\n",
    "            # Cria um ID único para o visualContainer\n",
    "            visual_container_id = visual_container_id_counter\n",
    "            visual_container_id_counter += 1\n",
    "\n",
    "            # Adiciona o ID do visualContainer à seção correspondente\n",
    "            sections_data[-1][\"VisualContainers_id\"].append(visual_container_id)\n",
    "\n",
    "            # Processa o campo config do visualContainer\n",
    "            config = json.loads(visual_container.get(\"config\", \"{}\"))\n",
    "            single_visual = config.get(\"singleVisual\", {})\n",
    "            prototype_query = single_visual.get(\"prototypeQuery\", {}).get(\"Select\", [])\n",
    "\n",
    "            # Determina se é um grupo (visualType vazio)\n",
    "            visual_type = single_visual.get(\"visualType\", \"\")\n",
    "            is_group = visual_type == \"\"\n",
    "\n",
    "            # Adiciona os dados do visualContainer à tabela df_visual_containers\n",
    "            visual_containers_data.append({\n",
    "                \"VisualContainers_id\": visual_container_id,\n",
    "                \"id_section\": section_id,\n",
    "                \"height\": visual_container.get(\"height\"),\n",
    "                \"width\": visual_container.get(\"width\"),\n",
    "                \"x\": visual_container.get(\"x\"),\n",
    "                \"y\": visual_container.get(\"y\"),\n",
    "                \"z\": visual_container.get(\"z\"),\n",
    "                \"name\": config.get(\"name\"),\n",
    "                \"visualType\": \"group\" if is_group else visual_type,\n",
    "                \"config\": visual_container.get(\"config\")  # Inclui o JSON completo no final\n",
    "            })\n",
    "\n",
    "            # Processa o prototypeQuery.Select para identificar colunas, medidas e agregações\n",
    "            for select_item in prototype_query:\n",
    "                tipo = None\n",
    "                table = None\n",
    "                column = None\n",
    "                aggregation = None\n",
    "                expression_type = None\n",
    "\n",
    "                # Determina o tipo com base nos campos presentes\n",
    "                if \"Column\" in select_item:\n",
    "                    tipo = \"column\"\n",
    "                    expression_type = \"Column\"\n",
    "                    table = select_item[\"Column\"].get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\")\n",
    "                    column = select_item[\"Column\"].get(\"Property\")\n",
    "                elif \"Aggregation\" in select_item:\n",
    "                    tipo = \"aggregation\"\n",
    "                    expression_type = \"Aggregation\"\n",
    "                    aggregation_value = select_item[\"Aggregation\"].get(\"Function\")\n",
    "                    aggregation_map = {1: \"SUM\", 2: \"AVG\", 3: \"COUNT\", 4: \"MIN\", 5: \"MAX\"}\n",
    "                    aggregation = aggregation_map.get(aggregation_value, f\"Unknown ({aggregation_value})\")\n",
    "                    table = select_item[\"Aggregation\"].get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\")\n",
    "                    column = select_item[\"Aggregation\"].get(\"Expression\", {}).get(\"Property\")\n",
    "                elif \"Measure\" in select_item:\n",
    "                    tipo = \"measure\"\n",
    "                    expression_type = \"Measure\"\n",
    "                    table = select_item[\"Measure\"].get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\")\n",
    "                    column = select_item[\"Measure\"].get(\"Property\")\n",
    "\n",
    "                # Adiciona os dados à tabela df_vc_complemento\n",
    "                vc_complemento_data.append({\n",
    "                    \"VisualContainers_id\": visual_container_id,\n",
    "                    \"tipo\": tipo,\n",
    "                    \"Tabela\": table,\n",
    "                    \"nome\": column,\n",
    "                    \"nomeNoVisual\": select_item.get(\"NativeReferenceName\", column),\n",
    "                    \"Agregacao\": aggregation,\n",
    "                    \"expression\": expression_type\n",
    "                })\n",
    "\n",
    "    # Converte as listas em DataFrames\n",
    "    df_sections = pd.DataFrame(sections_data)\n",
    "    df_visual_containers = pd.DataFrame(visual_containers_data)\n",
    "    df_vc_complemento = pd.DataFrame(vc_complemento_data)\n",
    "\n",
    "    return df_sections, df_visual_containers, df_vc_complemento\n",
    "\n",
    "# Caminho para o arquivo JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f3f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(json_data, df_sections, df_visual_containers):\n",
    "    \"\"\"\n",
    "    Processa a chave 'config' e gera as tabelas df_bookmarks e df_bookmark_detalhamento,\n",
    "    incluindo bookmarks com children, mantendo a hierarquia correta.\n",
    "    \"\"\"\n",
    "    # Listas para armazenar os dados das tabelas\n",
    "    bookmarks_data = []\n",
    "    bookmark_detalhamento_data = []\n",
    "\n",
    "    # IDs únicos para bookmarks\n",
    "    bookmark_id_counter = 1\n",
    "\n",
    "    # Processa os bookmarks na chave 'config'\n",
    "    config = json.loads(json_data.get(\"config\", \"{}\"))\n",
    "    bookmarks = config.get(\"bookmarks\", [])\n",
    "\n",
    "    def process_bookmark(bookmark, parent_id=None, parent_name=None, child_index=None):\n",
    "        nonlocal bookmark_id_counter\n",
    "\n",
    "        # Define o nome do pai e o ID do pai\n",
    "        id_pai = parent_id\n",
    "        nome_pai = parent_name\n",
    "\n",
    "        current_id = bookmark_id_counter  # Salva o ID atual do bookmark\n",
    "        bookmark_id_counter += 1  # Incrementa o contador de IDs  \n",
    "        \n",
    "        # Verifica se o campo options existe e extrai os subcampos\n",
    "        options = bookmark.get(\"options\", {})\n",
    "        apply_only_to_target_visuals = options.get(\"applyOnlytoTargetVisuals\", False)\n",
    "        supress_data = options.get(\"suppressData\", False)\n",
    "\n",
    "        # Extrai a seção do explorationState\n",
    "        exploration_state = bookmark.get(\"explorationState\", {})\n",
    "        sections_keys = list(exploration_state.get(\"sections\", {}).keys())\n",
    "        section_name = sections_keys[0] if sections_keys else None  # Verifica se há seções antes de acessar\n",
    "\n",
    "        # Relaciona os visualContainers ao id_bookmark\n",
    "        if section_name:  # Apenas processa se houver uma seção\n",
    "            visual_containers_data = exploration_state.get(\"sections\", {}).get(section_name, {})\n",
    "            visual_containers = visual_containers_data.get(\"visualContainers\", {})\n",
    "            visual_containers_groups = visual_containers_data.get(\"visualContainerGroups\", {})\n",
    "\n",
    "            # Processa VisualContainers\n",
    "            for visual_container_name in visual_containers:\n",
    "                # Busca o section_id correspondente na tabela df_sections\n",
    "                section_row = df_sections[df_sections[\"sections\"] == section_name]\n",
    "                section_id = section_row.iloc[0][\"id_section\"] if not section_row.empty else None\n",
    "\n",
    "                # Busca o visualContainers_id correspondente na tabela df_visual_containers\n",
    "                visual_container_row = df_visual_containers[df_visual_containers[\"name\"] == visual_container_name]\n",
    "                visual_container_id = visual_container_row.iloc[0][\"VisualContainers_id\"] if not visual_container_row.empty else None\n",
    "\n",
    "                # Adiciona o detalhamento ao df_bookmark_detalhamento\n",
    "                bookmark_detalhamento_data.append({\n",
    "                    \"id_bookmark\": current_id,\n",
    "                    \"section_name\": section_name,\n",
    "                    \"visual_container_name\": visual_container_name,\n",
    "                    \"section_id\": section_id,\n",
    "                    \"visualContainers_id\": visual_container_id,\n",
    "                    \"type\": \"VisualContainer\"\n",
    "                })\n",
    "\n",
    "            # Processa visualContainersGroup\n",
    "            for visual_container_group_name in visual_containers_groups:\n",
    "                # Busca o section_id correspondente na tabela df_sections\n",
    "                section_row = df_sections[df_sections[\"sections\"] == section_name]\n",
    "                section_id = section_row.iloc[0][\"id_section\"] if not section_row.empty else None\n",
    "\n",
    "                # Busca o visualContainers_id correspondente na tabela df_visual_containers\n",
    "                visual_container_row = df_visual_containers[df_visual_containers[\"name\"] == visual_container_group_name]\n",
    "                visual_container_id = visual_container_row.iloc[0][\"VisualContainers_id\"] if not visual_container_row.empty else None\n",
    "\n",
    "                # Adiciona o detalhamento ao df_bookmark_detalhamento\n",
    "                bookmark_detalhamento_data.append({\n",
    "                    \"id_bookmark\": current_id,\n",
    "                    \"section_name\": section_name,\n",
    "                    \"visual_container_name\": visual_container_group_name,\n",
    "                    \"section_id\": section_id,\n",
    "                    \"visualContainers_id\": visual_container_id,\n",
    "                    \"type\": \"VisualContainerGroup\"\n",
    "                })\n",
    "\n",
    "        # Processa os children, se existirem\n",
    "        children = bookmark.get(\"children\", [])\n",
    "        for index, child in enumerate(children):\n",
    "            process_bookmark(\n",
    "                child,\n",
    "                parent_id=current_id,\n",
    "                parent_name=bookmark.get(\"name\"),\n",
    "                child_index=index\n",
    "            )\n",
    "\n",
    "    # Processa cada bookmark\n",
    "    for index, bookmark in enumerate(bookmarks):\n",
    "        process_bookmark(bookmark, child_index=index)\n",
    "\n",
    "    # Converte as listas em DataFrames\n",
    "    df_bookmarks = pd.DataFrame(bookmarks_data)\n",
    "    df_bookmark_detalhamento = pd.DataFrame(bookmark_detalhamento_data)\n",
    "\n",
    "    return df_bookmarks, df_bookmark_detalhamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa74aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_config(json_data, df_sections, df_visual_containers):\n",
    "    \"\"\"\n",
    "    Processa a chave 'config' e gera as tabelas df_bookmarks e df_bookmark_detalhamento,\n",
    "    incluindo bookmarks com children, mantendo a hierarquia correta.\n",
    "    \"\"\"\n",
    "    # Listas para armazenar os dados das tabelas\n",
    "    bookmarks_data = []\n",
    "    bookmark_detalhamento_data = []\n",
    "\n",
    "    # IDs únicos para bookmarks\n",
    "    bookmark_id_counter = 1\n",
    "\n",
    "    # Processa os bookmarks na chave 'config'\n",
    "    config = json.loads(json_data.get(\"config\", \"{}\"))\n",
    "\n",
    "    bookmarks = config.get(\"bookmarks\", [])\n",
    "\n",
    "    def process_bookmark(bookmark, parent_id=None, parent_name=None, child_index=None):\n",
    "        nonlocal bookmark_id_counter\n",
    "\n",
    "        # Define o nome do pai e o ID do pai\n",
    "        id_pai = parent_id\n",
    "        nome_pai = parent_name\n",
    "\n",
    "        current_id = bookmark_id_counter  # Salva o ID atual do bookmark\n",
    "        bookmark_id_counter += 1  # Incrementa o contador de IDs  \n",
    "\n",
    "\n",
    "        # Verifica se o campo options existe e extrai os subcampos\n",
    "        options = bookmark.get(\"options\", {})\n",
    "        apply_only_to_target_visuals = options.get(\"applyOnlytoTargetVisuals\", False)\n",
    "        supress_data = options.get(\"suppressData\", False)\n",
    "\n",
    "        # Adiciona os dados do bookmark à lista\n",
    "        bookmarks_data.append({\n",
    "            \"id_bookmark\": current_id,\n",
    "            \"name\": bookmark.get(\"name\"),\n",
    "            \"displayName\": bookmark.get(\"displayName\"),\n",
    "            \"parent_id\": id_pai,\n",
    "            \"parent_name\": nome_pai,\n",
    "            \"child_index\": child_index,\n",
    "            \"applyOnlyToTargetVisuals\": apply_only_to_target_visuals,\n",
    "            \"suppressData\": supress_data\n",
    "        })\n",
    "\n",
    "        # Processa os children, se existirem\n",
    "        children = bookmark.get(\"children\", [])\n",
    "        for index, child in enumerate(children):\n",
    "            process_bookmark(\n",
    "                child,\n",
    "                parent_id=current_id,\n",
    "                parent_name=bookmark.get(\"name\"),\n",
    "                child_index=index\n",
    "            )\n",
    "\n",
    "    # Processa cada bookmark\n",
    "    for index, bookmark in enumerate(bookmarks):\n",
    "        process_bookmark(bookmark, child_index=index)\n",
    "\n",
    "    # Converte as listas em DataFrames\n",
    "    df_bookmarks = pd.DataFrame(bookmarks_data)\n",
    "    df_bookmark_detalhamento = pd.DataFrame(bookmark_detalhamento_data)\n",
    "\n",
    "    return df_bookmarks, df_bookmark_detalhamento\n",
    "\n",
    "df_bookmarks, df_bookmark_detalhamento = process_config(json_data,df_sections,df_visual_containers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522fc4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explore_visual_containers(data):\n",
    "    \"\"\"\n",
    "    Explora o JSON no caminho config -> bookmarks -> explorationState -> sections -> visualContainers\n",
    "    e converte os dados em uma tabela estruturada (DataFrame).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # Verifica se o campo config existe e é um JSON válido\n",
    "    config = json.loads(data.get(\"config\", \"{}\"))\n",
    "    bookmarks = config.get(\"bookmarks\", [])\n",
    "\n",
    "    # Itera sobre os bookmarks\n",
    "    for bookmark in bookmarks:\n",
    "        bookmark_name = bookmark.get(\"displayName\", \"Sem Nome\")\n",
    "        bookmark_id = bookmark.get(\"name\", \"Sem ID\")\n",
    "        exploration_state = bookmark.get(\"explorationState\", {})\n",
    "        sections = exploration_state.get(\"sections\", {})\n",
    "\n",
    "        # Itera sobre as sections dentro do explorationState\n",
    "        for section_id, section_data in sections.items():\n",
    "            visual_containers = section_data.get(\"visualContainers\", {})\n",
    "\n",
    "            # Itera sobre os visualContainers\n",
    "            for vc_id, vc_data in visual_containers.items():\n",
    "                filters = vc_data.get(\"filters\", {}).get(\"byExpr\", [])\n",
    "                single_visual = vc_data.get(\"singleVisual\", {})\n",
    "                visual_type = single_visual.get(\"visualType\", \"Desconhecido\")\n",
    "\n",
    "                # Itera sobre os filtros (byExpr)\n",
    "                for filter_item in filters:\n",
    "                    filter_type = filter_item.get(\"type\", \"Desconhecido\")\n",
    "                    expression = filter_item.get(\"expression\", {})\n",
    "                    column_data = expression.get(\"Column\", {}) or \\\n",
    "                        expression.get(\"Aggregation\", {}).get(\"Expression\", {}).get(\"Column\", {}) or \\\n",
    "                        expression.get(\"Measure\", {})\n",
    "                    table = column_data.get(\"Expression\", {}).get(\"SourceRef\", {}).get(\"Entity\", \"Desconhecido\") \n",
    "                    property_name = column_data.get(\"Property\", \"Desconhecido\")\n",
    "\n",
    "                    # Adiciona os dados à lista\n",
    "                    rows.append({\n",
    "                        \"Bookmark Name\": bookmark_name,\n",
    "                        \"Bookmark ID\": bookmark_id,\n",
    "                        \"Section ID\": section_id,\n",
    "                        \"VisualContainer ID\": vc_id,\n",
    "                        \"Visual Type\": visual_type,\n",
    "                        \"Filter Type\": filter_type,\n",
    "                        \"Table\": table,\n",
    "                        \"Column\": property_name\n",
    "                    })\n",
    "\n",
    "    # Converte os dados em um DataFrame\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Caminho para o arquivo JSON\n",
    "json_file = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report.json\"\n",
    "\n",
    "# Carrega o JSON\n",
    "with open(json_file, 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Explora os visualContainers e cria a tabela\n",
    "df_visual_containers = explore_visual_containers(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917a6cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"processed_rows = []\\n\\n# Itera sobre os dados do DataFrame df_visual_byexpr\\nfor index, row in df_visual_byexpr.iterrows():\\n    by_expr_item = json.loads(row['byExprItem'])  # Converte o JSON string de volta para dicionário\\n    item_type = by_expr_item.get('type')  # Obtém o campo 'type'\\n    expression = by_expr_item.get('expression', {})  # Obtém o campo 'expression'\\n    source_ref = expression.get('Column', {}).get('Expression', {}).get('SourceRef', {}).get('Entity')  # Obtém o 'sourceRef'\\n    property_name = expression.get('Column', {}).get('Property')  # Obtém o 'property'\\n    \\n    # Adiciona os dados processados à lista\\n    processed_rows.append({\\n        'visualName': row['visualName'],\\n        'visualType': row['visualType'],\\n        'type': item_type,\\n        'sourceRef': source_ref,\\n        'property': property_name,\\n        'byExprIndex': index  # Índice do item da byExpr\\n    })\\n\\n# Converte a lista em um novo DataFrame\\ndf_processed_byexpr = pd.DataFrame(processed_rows)\\n\\n# Exibe o DataFrame resultante\\ndf_processed_byexpr\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"processed_rows = []\n",
    "\n",
    "# Itera sobre os dados do DataFrame df_visual_byexpr\n",
    "for index, row in df_visual_byexpr.iterrows():\n",
    "    by_expr_item = json.loads(row['byExprItem'])  # Converte o JSON string de volta para dicionário\n",
    "    item_type = by_expr_item.get('type')  # Obtém o campo 'type'\n",
    "    expression = by_expr_item.get('expression', {})  # Obtém o campo 'expression'\n",
    "    source_ref = expression.get('Column', {}).get('Expression', {}).get('SourceRef', {}).get('Entity')  # Obtém o 'sourceRef'\n",
    "    property_name = expression.get('Column', {}).get('Property')  # Obtém o 'property'\n",
    "    \n",
    "    # Adiciona os dados processados à lista\n",
    "    processed_rows.append({\n",
    "        'visualName': row['visualName'],\n",
    "        'visualType': row['visualType'],\n",
    "        'type': item_type,\n",
    "        'sourceRef': source_ref,\n",
    "        'property': property_name,\n",
    "        'byExprIndex': index  # Índice do item da byExpr\n",
    "    })\n",
    "\n",
    "# Converte a lista em um novo DataFrame\n",
    "df_processed_byexpr = pd.DataFrame(processed_rows)\n",
    "\n",
    "# Exibe o DataFrame resultante\n",
    "df_processed_byexpr\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e25227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Excel gerado: c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\report_compilado.xlsx\n"
     ]
    }
   ],
   "source": [
    "json_file = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report.json\"\n",
    "\n",
    "# Carrega o JSON\n",
    "with open(json_file, 'r', encoding='utf-8') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Processa as sections e config\n",
    "df_sections, df_visual_containers, df_vc_complemento = process_sections(json_data)\n",
    "df_bookmarks, df_bookmark_detalhamento = process_config(json_data,df_sections,df_visual_containers)\n",
    "\n",
    "df_visual_containers_complemento = explore_visual_containers(json_data)\n",
    "# Caminho para salvar o arquivo Excel\n",
    "output_excel = r\"c:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\report_compilado.xlsx\"\n",
    "\n",
    "# Exporta os DataFrames para um único arquivo Excel\n",
    "with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
    "    df_sections.to_excel(writer, sheet_name=\"Sections\", index=False)\n",
    "    df_visual_containers.to_excel(writer, sheet_name=\"VisualContainers\", index=False)\n",
    "    df_visual_containers_complemento.to_excel(writer, sheet_name=\"VisualContainers_complemento\", index=False)\n",
    "    df_vc_complemento.to_excel(writer, sheet_name=\"VC_Complemento\", index=False)\n",
    "    df_bookmarks.to_excel(writer, sheet_name=\"Bookmarks\", index=False)\n",
    "    df_bookmark_detalhamento.to_excel(writer, sheet_name=\"Bookmark_Detalhamento\", index=False)\n",
    "\n",
    "print(f\"Arquivo Excel gerado: {output_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eccaddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo modificado salvo como 'C:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report_modified.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Caminho para o arquivo JSON original\n",
    "input_file = r'C:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report.json'\n",
    "output_file = r'C:\\Users\\renat\\Downloads\\Material Referência_Estudo\\Estudo PBIP\\BPIP Demo\\Demo.Report\\report_modified.json'\n",
    "\n",
    "# Carregar o arquivo JSON original\n",
    "with open(input_file, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Verificar se a chave \"config\" existe e é uma string\n",
    "if \"config\" in data and isinstance(data[\"config\"], str):\n",
    "    # Desserializar o valor da chave \"config\" (JSON dentro de uma string)\n",
    "    config = json.loads(data[\"config\"])\n",
    "    \n",
    "    # Localizar a lista de bookmarks\n",
    "    bookmarks = config.get(\"bookmarks\", [])\n",
    "\n",
    "    # Verificar se a lista de bookmarks existe\n",
    "    if isinstance(bookmarks, list):\n",
    "        # Procurar o bookmark com displayName 'P2_PT_Bar' e id '77061bd1b5ebe593a6b1'\n",
    "        bookmark_found = False\n",
    "        for bookmark in bookmarks:\n",
    "            if bookmark.get('displayName') == 'P2_PT_Bar' and bookmark.get('name') == '77061bd1b5ebe593a6b1':\n",
    "                # Fazer uma cópia do bookmark\n",
    "                new_bookmark = bookmark.copy()\n",
    "                # Alterar os valores solicitados\n",
    "                new_bookmark['displayName'] = 'SUPER_TESTE'\n",
    "                new_bookmark['name'] = ''\n",
    "                # Adicionar o novo bookmark ao final da lista\n",
    "                bookmarks.append(new_bookmark)\n",
    "                bookmark_found = True\n",
    "                break\n",
    "\n",
    "        if not bookmark_found:\n",
    "            print(\"Bookmark com displayName 'P2_PT_Bar' e id '77061bd1b5ebe593a6b1' não encontrado.\")\n",
    "    else:\n",
    "        print(\"A chave 'bookmarks' não é uma lista ou não existe no JSON dentro de 'config'.\")\n",
    "\n",
    "    # Serializar novamente o dicionário \"config\" para uma string JSON\n",
    "    data[\"config\"] = json.dumps(config)\n",
    "else:\n",
    "    print(\"A chave 'config' não existe ou não é uma string no arquivo JSON.\")\n",
    "\n",
    "# Salvar o arquivo modificado em uma nova cópia\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Arquivo modificado salvo como '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
